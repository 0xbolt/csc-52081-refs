# csc-52081-refs
References and suggested readings for CSC-52081. Generated partially by ChatGPT.

> Please note that these are unofficial course notes. They may contains mistakes.

## Schedule
| Course Session | Topics Covered | Sutton & Barto (Primary Text) | Additional References | Suggested Readings |
| --- | --- | --- | --- | --- |
| Session 1 – Probabilistic Reasoning and Decision Making | • Autonomous / rational agents <br> • Observation → state → action → reward pipeline <br> • Decision theory & expected reward <br> • Bayesian Networks (DAGs, factorization) <br> • Conditional independence & explaining away <br> • Stochastic processes <br> • Markov property & Markov processes <br> • HMM intuition <br> • POMDP intuition <br> • Planning vs decision making <br> • Imitation & model learning (conceptual) | Ch. 1.1–1.3 – RL problem & agents <br> Ch. 3.1–3.3 – Agent–Environment Interface, Rewards <br> Ch. 3.5–3.6 – Markov Property, MDPs <br> Ch. 4 (conceptual) – Planning as optimization | • Koller & Friedman (2009), Probabilistic Graphical Models <br> • Murphy (2012), ML: A Probabilistic Perspective <br> • Rabiner (1989), HMM tutorial <br> • Kaelbling et al. (1998), POMDP survey | • Sutton (2019), “The Bitter Lesson” — why general methods (search + learning) matter more than handcrafted knowledge <br> • Murphy Ch. 10 (Bayesian inference) <br> • Rabiner HMM tutorial (intuition only) |
| Session 2 – Bandit Machines (and MCTS) | • Multi-armed bandits <br> • Regret & sequential decisions <br> • Exploration vs exploitation <br> • ε-greedy <br> • UCB (Upper Confidence Bounds) <br> • Regret guarantees (high-level) <br> • Thompson Sampling (Bayesian bandits) <br> • EXP3 (adversarial bandits, importance sampling) <br> • Contextual bandits <br> • Monte Carlo Tree Search (MCTS) <br> • UCT (UCB for Trees) | Ch. 2.1–2.3 – Bandits, ε-greedy <br> Ch. 2.6 – UCB <br> Ch. 2.8 – Contextual bandits <br> Ch. 8.7–8.8 – Planning & MCTS intuition | • Auer et al. (2002) – UCB & EXP3 <br> • Lattimore & Szepesvári (2020), Bandit Algorithms <br> • Russo et al. (2018), Thompson Sampling tutorial <br> • Kocsis & Szepesvári (2006), UCT | • Lattimore & Szepesvári Ch. 1–3 (regret & exploration theory) <br> • Auer et al. (2002) for regret bounds <br> • Kocsis & Szepesvári (2006) for UCT |
